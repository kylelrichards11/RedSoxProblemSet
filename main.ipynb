{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitredsoxpscondae1983f7c7e0f40968437aab0fab66697",
   "display_name": "Python 3.7.9 64-bit ('redsoxps': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cuml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "import xgboost as xgb\n",
    "\n",
    "import data\n",
    "import features\n",
    "from training import calc_result_stats, split_X_y, train\n",
    "from utils import print_time, write_dict"
   ]
  },
  {
   "source": [
    "# Load Data\n",
    "Load the data, only keeping the columns that we can use in both the training and holdout sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"AwayScore\",\n",
    "    \"B1\",\n",
    "    \"B2\",\n",
    "    \"B3\",\n",
    "    \"Balls\",\n",
    "    \"BatterHand\",\n",
    "    \"DayNight\",\n",
    "    \"GameDate\",\n",
    "    \"GameNumber\",\n",
    "    \"GameSeqNum\",\n",
    "    \"HomeScore\",\n",
    "    \"Inning\",\n",
    "    \"Outs\",\n",
    "    \"PAOfInning\",\n",
    "    \"PitchBreakHorz\",\n",
    "    \"PitchBreakVert\",\n",
    "    \"PitchOfPA\",\n",
    "    \"PitchResult\",\n",
    "    \"PitchType\",\n",
    "    \"PitcherHand\",\n",
    "    \"PitcherID\",\n",
    "    \"PlateLocX\",\n",
    "    \"PlateLocZ\",\n",
    "    \"ReleaseLocX\",\n",
    "    \"ReleaseLocY\",\n",
    "    \"ReleaseLocZ\",\n",
    "    \"ReleaseSpeed\",\n",
    "    \"ReleaseVelocityX\",\n",
    "    \"ReleaseVelocityY\",\n",
    "    \"ReleaseVelocityZ\",\n",
    "    \"Season\",\n",
    "    \"SpinRate\",\n",
    "    \"Strikes\",\n",
    "    \"TopInning\",\n",
    "]\n",
    "\n",
    "df = data.load_train(columns=cols)\n",
    "df_test = data.load_holdout()\n",
    "df_test_original = data.load_holdout()"
   ]
  },
  {
   "source": [
    "# Clean Data\n",
    "Here we One Hot Encode all categorical columns, make the label column (SwingAndMiss), and then set the index to a unique index. Each of these functions can be found in the data.py file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = data.one_hot_encode(df)\n",
    "    df = data.set_index(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data(df)\n",
    "df = data.make_label(df)\n"
   ]
  },
  {
   "source": [
    "# Create Features\n",
    "I decided to create some manual features that I thought could be helpful in creating predictions. Below I create those feautres. The code for each function can be found in features.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = features.appearance_gap(df)\n",
    "    df = features.pa_of_game(df)\n",
    "    df = features.pa_of_season(df)\n",
    "    df = features.pitch_of_game(df)\n",
    "    df = features.pitch_of_game_pitch_type(df)\n",
    "    df = features.pitch_of_season(df)\n",
    "    df = features.cumulative_avg_movements_game(df)\n",
    "    df = features.cumulative_avg_velocities_game(df)\n",
    "    df = features.runs_ahead(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_features(df)"
   ]
  },
  {
   "source": [
    "# Remove any Intermediate Features\n",
    "I also removed any features for the Knuckleball pitch type because there were no knuckleballs thrown in the holdout set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "    \"Inning\",\n",
    "    \"PAOfInning\",\n",
    "    \"PitchOfPA\",\n",
    "    \"Balls\",\n",
    "    \"Strikes\",\n",
    "    \"Outs\",\n",
    "    \"B1\",\n",
    "    \"B2\",\n",
    "    \"B3\",\n",
    "    \"ReleaseLocX\",\n",
    "    \"ReleaseLocY\",\n",
    "    \"ReleaseLocZ\",\n",
    "    \"ReleaseVelocityX\",\n",
    "    \"ReleaseVelocityY\",\n",
    "    \"ReleaseVelocityZ\",\n",
    "    \"ReleaseSpeed\",\n",
    "    \"PitchBreakVert\",\n",
    "    \"PitchBreakHorz\",\n",
    "    \"SpinRate\",\n",
    "    \"PlateLocX\",\n",
    "    \"PlateLocZ\",\n",
    "    \"BatterHand_L\",\n",
    "    \"PitcherHand_L\",\n",
    "    \"DayNight_Day\",\n",
    "    \"PitchType_CB\",\n",
    "    \"PitchType_CF\",\n",
    "    \"PitchType_CH\",\n",
    "    \"PitchType_FB\",\n",
    "    \"PitchType_SF\",\n",
    "    \"PitchType_SI\",\n",
    "    \"TopInning_BOTTOM\",\n",
    "    \"AppearanceGap\",\n",
    "    \"PAOfGame\",\n",
    "    \"PAOfSeason\",\n",
    "    \"PitchOfGame\",\n",
    "    \"PitchOfGameCB\",\n",
    "    \"PitchOfGameCF\",\n",
    "    \"PitchOfGameCH\",\n",
    "    \"PitchOfGameFB\",\n",
    "    \"PitchOfGameSF\",\n",
    "    \"PitchOfGameSI\",\n",
    "    \"PitchOfGameSL\",\n",
    "    \"PitchOfSeason\",\n",
    "    \"PitchBreakHorzAvgGame\",\n",
    "    \"PitchBreakHorzAvgGameCB\",\n",
    "    \"PitchBreakHorzAvgGameCF\",\n",
    "    \"PitchBreakHorzAvgGameCH\",\n",
    "    \"PitchBreakHorzAvgGameFB\",\n",
    "    \"PitchBreakHorzAvgGameSF\",\n",
    "    \"PitchBreakHorzAvgGameSI\",\n",
    "    \"PitchBreakHorzAvgGameSL\",\n",
    "    \"PitchBreakVertAvgGame\",\n",
    "    \"PitchBreakVertAvgGameCB\",\n",
    "    \"PitchBreakVertAvgGameCF\",\n",
    "    \"PitchBreakVertAvgGameCH\",\n",
    "    \"PitchBreakVertAvgGameFB\",\n",
    "    \"PitchBreakVertAvgGameSF\",\n",
    "    \"PitchBreakVertAvgGameSI\",\n",
    "    \"PitchBreakVertAvgGameSL\",\n",
    "    \"PitcherID\",\n",
    "    \"ReleaseSpeedAvgGame\",\n",
    "    \"ReleaseSpeedAvgGameCB\",\n",
    "    \"ReleaseSpeedAvgGameCF\",\n",
    "    \"ReleaseSpeedAvgGameCH\",\n",
    "    \"ReleaseSpeedAvgGameFB\",\n",
    "    \"ReleaseSpeedAvgGameSF\",\n",
    "    \"ReleaseSpeedAvgGameSI\",\n",
    "    \"ReleaseSpeedAvgGameSL\",\n",
    "    \"RunsAhead\",\n",
    "]\n",
    "df = df.loc[:, final_cols + [\"SwingAndMiss\"]]"
   ]
  },
  {
   "source": [
    "# Training\n",
    "I decided to use a tree based model for this classification problem. The main reason for this was the project requirement to report \"what inputs to your model(s) seem to be driving that prediction for that\n",
    "particular pitch the most?\" With tree based methods, it is very easy to see which features are most important in the classification. \n",
    "\n",
    "Because the classes are very imbalanced, I use the scale_pos_weight parameter of the XGBoost tree to train the model with respect to SwingAndMisses more. When I tried models without weighting, they had a high accuracy, but poor f1 score as they were producing predictions of all not a swing and miss.\n",
    "\n",
    "I use cross validation in order to tune two parameters in this model: max_depth and scale_pos_weight. The cross validation function is written in train.py as train(). \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for weight in range(2, 11):\n",
    "    for max_depth in range(4, 13, 2):\n",
    "        clf = xgb.XGBClassifier(\n",
    "            eval_metric=\"auc\",\n",
    "            gamma=0,\n",
    "            objective=\"binary:logistic\",\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=1000,\n",
    "            scale_pos_weight=weight,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        results = train(df, clf, feature_selection=None)\n",
    "        stats = calc_result_stats(results)\n",
    "        all_results.append({\n",
    "            \"gamma\" : 0,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"stats\": stats,\n",
    "            \"weight\" : weight,\n",
    "        })\n",
    "all_results = sorted(all_results, key = lambda i : i[\"stats\"][\"val_acc_1_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model\n",
    "clf = xgb.XGBClassifier(\n",
    "    eval_metric=\"auc\",\n",
    "    gamma=0,\n",
    "    objective=\"binary:logistic\",\n",
    "    max_depth=4,\n",
    "    n_estimators=1000,\n",
    "    scale_pos_weight=9,\n",
    "    tree_method=\"gpu_hist\",\n",
    "    use_label_encoder=False\n",
    ")\n",
    "train_X, train_y = split_X_y(df)\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "df_test = clean_data(df_test)\n",
    "df_test = create_features(df_test)\n",
    "df_test = df_test.loc[:, final_cols]\n",
    "holdout_predictions = clf.predict(df_test)\n",
    "df_test[\"Prediction\"] = holdout_predictions\n",
    "df_test = df_test.to_pandas()\n",
    "\n",
    "# Save original DataFrame with predictions to csv\n",
    "df_test_original = df_test_original.to_pandas()\n",
    "df_test_original[\"Prediction\"] = holdout_predictions\n",
    "df_test_original.to_csv(\"Predictions.csv\", index=False)"
   ]
  },
  {
   "source": [
    "# Results\n",
    "Because the data is imbalanced, I had to decide how to balance overall accuracy and accuracy per class for my final model. I decided to choose a model with a high True Positive rate for predicting a swing and miss; at the cost of a high false positive rate for predicting not a swing and miss. I mainly made this decision because the problem set is interested in determining what factors lead to swing and misses. A model that is biased more towards predicting swing and misses will be better suited for this.\n",
    "\n",
    "The final parameters I chose were a class weight of 9 and a max depth of 4.\n",
    "\n",
    "Because XGBoost uses a forest of trees, there is no definite order of what features are the most important. However, I aggregated the number of times a feature appeared in the first 7 splits (3 layers of the tree). The following table shows how many times the feature appeared in the tree.\n",
    "\n",
    "| Feature | Appearances |\n",
    "|------|------|\n",
    "| PlateLocX | 500 |\n",
    "| PlateLocZ | 483 |\n",
    "| ReleaseVelocityX | 308 |\n",
    "| PitchBreakVert | 305 |\n",
    "| PitchBreakHorz | 260 |\n",
    "| ReleaseLocX | 208 |\n",
    "| ReleaseVelocityZ | 302 |\n",
    "| ReleaseLocZ | 189 |\n",
    "| SpinRate | 170 |\n",
    "| ReleaseLocY | 168 |\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Find pitchers with best swing and miss rate\n",
    "The final part of the problem set is to identify which pitchers and pitches in the holdout set are the best at creating swing and misses. To do this, for each holdout pitcher I calculated the number of swing and miss pitches. I then removed any pitchers that were in the lower quartile of pitches thrown to make sure there was an adequate sample size for each pitcher. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                     SwingAndMissCt  PitchCount  SwingAndMissAvg\nPitcherID PitchType                                             \n363727    FB                    583        1483         0.393122\n353975    FB                    582        1537         0.378660\n353472    SL                    552         965         0.572021\n          FB                    519        1334         0.389055\n353975    SL                    468         986         0.474645\n...                             ...         ...              ...\n408384    SI                     15          83         0.180723\n363201    CB                     15          56         0.267857\n334902    SI                     14         102         0.137255\n340757    SI                     13          56         0.232143\n348223    CB                     13          50         0.260000\n\n[240 rows x 3 columns]\n                     SwingAndMissCt  PitchCount  SwingAndMissAvg\nPitcherID PitchType                                             \n354630    SL                     34          50         0.680000\n305270    CB                     51          75         0.680000\n348223    CH                    414         634         0.652997\n363960    SL                     39          61         0.639344\n770286    SL                     93         146         0.636986\n...                             ...         ...              ...\n408384    SI                     15          83         0.180723\n354629    SI                    201        1138         0.176626\n369665    SI                     15          96         0.156250\n329950    SI                     21         150         0.140000\n334902    SI                     14         102         0.137255\n\n[240 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "swing_and_miss_ct = df_test_original.groupby([\"PitcherID\", \"PitchType\"]).apply(lambda g : g[\"Prediction\"].sum())\n",
    "pitch_count = df_test_original.groupby([\"PitcherID\", \"PitchType\"]).apply(lambda g : g.shape[0])\n",
    "holdout_results = pd.concat((swing_and_miss_ct, pitch_count), axis=1)\n",
    "holdout_results.columns=[\"SwingAndMissCt\", \"PitchCount\"]\n",
    "holdout_results[\"SwingAndMissAvg\"] = holdout_results[\"SwingAndMissCt\"]/holdout_results[\"PitchCount\"]\n",
    "pitch_count_cutoff = holdout_results[\"PitchCount\"].quantile(q=0.25)\n",
    "holdout_results = holdout_results[holdout_results[\"PitchCount\"] > pitch_count_cutoff]\n",
    "print(holdout_results.sort_values(by=\"SwingAndMissCt\", ascending=False))\n",
    "print(holdout_results.sort_values(by=\"SwingAndMissAvg\", ascending=False))"
   ]
  },
  {
   "source": [
    "# Future Work\n",
    "Overall I feel as though there are a lot of improvements that can be made to my work. Firstly, I do not use any temporal component in my model, which could definitely improve accuracy. I could create features based on the results of the most recent previous pitches. Additionally, time series models such as an LSTM could prove useful. \n",
    "\n",
    "I did not spend any time trying neural networks due to the interpretability requirements of the assignment, but there are still ways to use feature selection algorithms in combination with neural networks to see what factors are contributing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}